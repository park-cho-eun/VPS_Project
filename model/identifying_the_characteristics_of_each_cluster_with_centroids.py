# -*- coding: utf-8 -*-
"""Identifying the characteristics of each cluster with centroids

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MVfeCdqtE_TG8qgLaL2eLwXdavqc2AAl

# DBSCANNED 군집 centroid에 가장 가까운 기사 수집
"""

#데이터 불러오기
df = pd.read_json('C:\\Users\\clstm_\\OneDrive\\Desktop\\pro\\stalking_DBscanned.json')
cols = df.columns

import math
import numpy as np

for num, col in enumerate(cols[5:9]):
    # 각 군집의 중심이 되는 점과 가장 가까운 3개의 기사 벡터 수집
    closests = []
    for i in tqdm.tqdm(range(df[col].nunique())):
        i = i-1
        points_of_cluster_0 = df[df[col] == i]['2dim'].apply(lambda x:np.array(x))

        # 각 군집의 중심이 되는 위치 계산
        centroid_of_cluster_0 = np.mean(points_of_cluster_0, axis=0)
        target_x, target_y = centroid_of_cluster_0

        lent = df[df[col] == i].shape[0]
        min_distance = float('inf')
        closest_points = []

        for z in range(lent):
            x = df[df[col] == i]['embedding_x'].tolist()[z]
            y = df[df[col] == i]['embedding_y'].tolist()[z]

            # 중심과 각 벡터 값 간의 거리 계산
            distance = math.sqrt((x - target_x)**2 + (y - target_y)**2)
            data_point = [x, y]

            # 중심에 가장 가까운 3개의 기사 벡터 수집
            if len(closest_points) < 3:
                closest_points.append(data_point)
                closest_points.sort(key=lambda x:x[1])  # 거리 순으로 정렬
            elif distance < closest_points[-1][1]:
                closest_points.pop()
                closest_points.append(data_point)
                closest_points.sort(key=lambda x:x[1])  # 거리 순으로 정렬

        closests.append(closest_points)

    #각 군집을 대표하는 기사 3개씩 수집
    news = []
    label = []
    for k in range(len(closests)):
        for z in range(3):
            for r in range(df.shape[0]):
                if closests[k][z] == df.iloc[r, 2]:
                    news.append(df.iloc[r, 0])
                    label.append(r)

    new = pd.DataFrame(zip(news, label), columns=['sliced', 'label'])
    new.to_json('clustered_{}.json'.format(num))

"""# 군집별 대표 기사 요약"""

df = pd.read_excel('/content/cls1_summed.xlsx')
print(df)

import tqdm

summs = []
for i in tqdm.tqdm(range(df.shape[0])):
  cont = df.iloc[i, 4]
  ask = '아래의 기사를 한글로 한 줄 요약 해줘 \n \n' + cont
  response = openai.ChatCompletion.create(
  model="gpt-3.5-turbo",
  messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": ask},
        {"role": "assistant", "content": "Who's there?"}], temperature=0)

  result = response['choices'][0]['message']['content']
  summs.append(result)

df['summarized'] = summs
df = df[['sliced', 'label', 'cluster_label', 'summarized']]
df.to_excel('/content/cls1_summed_notall.xlsx')